{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjWWi775m--4",
        "outputId": "abc897e2-41e4-4310-cff9-fcd655b3fac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "import pandas as pd\n",
        "from textblob import Word\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "# import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split \n",
        "import wordcloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "9b7dmdBMnUUG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Mounting G-drive\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnRh6V7nnWNU",
        "outputId": "130aa72e-3d2b-40c5-e9a2-21862086f07b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loading dataset for analysis\n",
        "\"\"\"\n",
        "\n",
        "df = pd.read_csv(r\"/content/drive/MyDrive/Airline_Sentiment_analysis/dataset/Usecase3_Customer_Sentiment_Dataset.csv\")"
      ],
      "metadata": {
        "id": "S4xlCqU_nZ6L"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LC9RGrbvnf69",
        "outputId": "a55c0ad2-4601-4528-f54e-17dd282b9cdf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  airline_sentiment         airline  \\\n",
              "0           neutral  Virgin America   \n",
              "1          positive  Virgin America   \n",
              "2           neutral  Virgin America   \n",
              "3          negative  Virgin America   \n",
              "4          negative  Virgin America   \n",
              "\n",
              "                                                text  \n",
              "0                @VirginAmerica What @dhepburn said.  \n",
              "1  @VirginAmerica plus you've added commercials t...  \n",
              "2  @VirginAmerica I didn't today... Must mean I n...  \n",
              "3  @VirginAmerica it's really aggressive to blast...  \n",
              "4  @VirginAmerica and it's a really big bad thing...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-458c4c42-7386-431f-9206-f73f4b71e278\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-458c4c42-7386-431f-9206-f73f4b71e278')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-458c4c42-7386-431f-9206-f73f4b71e278 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-458c4c42-7386-431f-9206-f73f4b71e278');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df.airline_sentiment.value_counts()"
      ],
      "metadata": {
        "id": "pvI9Kyhx43pY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_class_count = class_counts.min()\n",
        "min_class_count\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFKMnXio43ss",
        "outputId": "67cb488f-a067-4cef-e8b4-d8f56e7d06cc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2363"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_data = pd.concat([df[df['airline_sentiment'] == class_].sample(min_class_count) for class_ in class_counts.index])\n"
      ],
      "metadata": {
        "id": "lOhm64cC43vZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the resulting DataFrame\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "FwjBEX1K5yKz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = balanced_data"
      ],
      "metadata": {
        "id": "3ogTi6Nx5yOA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHFqu-7u5yQr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tweet_preprocessor(tweet):\n",
        "    # precprcess tweet\n",
        "    tweet_words = []\n",
        "\n",
        "    for word in tweet.split(' '):\n",
        "        if word.startswith('@') and len(word) > 1:\n",
        "            word = '@user'\n",
        "        \n",
        "        elif word.startswith('http'):\n",
        "            word = \"http\"\n",
        "        tweet_words.append(word)\n",
        "\n",
        "    tweet_proc = \" \".join(tweet_words)\n",
        "    return tweet_proc"
      ],
      "metadata": {
        "id": "q7kVRJ7enio3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(lambda x: tweet_preprocessor(x))"
      ],
      "metadata": {
        "id": "94VR7DWlnk9H"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoded the target column\n",
        "lb=LabelEncoder()\n",
        "df['Label'] = lb.fit_transform(df['airline_sentiment'])"
      ],
      "metadata": {
        "id": "FIA4h5PJntMd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Embeddings using tokenizer\n",
        "tokenizer = Tokenizer(num_words=500, split=' ') \n",
        "tokenizer.fit_on_texts(df['text'].values)\n",
        "X = tokenizer.texts_to_sequences(df['text'].values)\n",
        "X = pad_sequences(X)"
      ],
      "metadata": {
        "id": "5nb-IPbqn1Je"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building\n",
        "model = Sequential()\n",
        "model.add(Embedding(500, 120, input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(352, activation='LeakyReLU'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7OE6p7qn8kN",
        "outputId": "856ea036-dde9-4cd8-b5e2-6ba74b64b6fb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 30, 120)           60000     \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 30, 120)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 704)               2323200   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 352)               248160    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 1059      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,632,419\n",
            "Trainable params: 2,632,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into training and testing\n",
        "y=pd.get_dummies(df['Label'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "nRiYkdZ8oFAd"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training\n",
        "batch_size=32\n",
        "model.fit(X_train, y_train, epochs = 15, batch_size=batch_size, verbose = 'auto')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR8RPvhtoJXv",
        "outputId": "77334751-ee98-4b04-a917-d734b5c2ffb0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "178/178 [==============================] - 60s 319ms/step - loss: 0.9120 - accuracy: 0.5639\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 32s 181ms/step - loss: 0.7245 - accuracy: 0.6904\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 34s 189ms/step - loss: 0.6452 - accuracy: 0.7244\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 32s 180ms/step - loss: 0.6092 - accuracy: 0.7494\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 34s 190ms/step - loss: 0.5828 - accuracy: 0.7579\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 30s 171ms/step - loss: 0.5502 - accuracy: 0.7718\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 36s 200ms/step - loss: 0.5329 - accuracy: 0.7824\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 32s 177ms/step - loss: 0.5079 - accuracy: 0.7960\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 33s 188ms/step - loss: 0.4990 - accuracy: 0.7976\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 31s 173ms/step - loss: 0.4701 - accuracy: 0.8096\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 33s 183ms/step - loss: 0.4643 - accuracy: 0.8096\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 30s 171ms/step - loss: 0.4418 - accuracy: 0.8198\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 33s 184ms/step - loss: 0.4259 - accuracy: 0.8254\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 32s 181ms/step - loss: 0.4100 - accuracy: 0.8344\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 30s 170ms/step - loss: 0.4010 - accuracy: 0.8355\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f53487c8c70>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Testing\n",
        "print(r\"NN test score on 20% split: \")\n",
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP11bCBtoQuX",
        "outputId": "9a195953-5368-4497-d2db-f7683fc13b4e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN test score on 20% split: \n",
            "45/45 [==============================] - 1s 14ms/step - loss: 0.8909 - accuracy: 0.6939\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8909470438957214, 0.6939350962638855]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(tweet):\n",
        "    # Tokenize and pad the input tweet\n",
        "    tweet_seq = tokenizer.texts_to_sequences([tweet])\n",
        "    tweet_padded = pad_sequences(tweet_seq, maxlen=X.shape[1], padding='post')\n",
        "    \n",
        "    # Make the prediction\n",
        "    sentiment_probs = model.predict(tweet_padded)[0]\n",
        "    \n",
        "    # Map the predicted sentiment probabilities to the sentiment labels\n",
        "    sentiment_labels = ['negative', 'neutral', 'positive']\n",
        "    predicted_sentiment = sentiment_labels[np.argmax(sentiment_probs)]\n",
        "    \n",
        "    return predicted_sentiment"
      ],
      "metadata": {
        "id": "BeB8j2HEqSj6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"This airline is the worst. I will never fly with them again.\"\n",
        "predicted_sentiment = predict_sentiment(tweet)\n",
        "print(predicted_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok_0zdY1qYgL",
        "outputId": "a9c283ff-56d7-42b1-8901-4e1a1784cd26"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 344ms/step\n",
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"I can fly with them again\"\n",
        "predicted_sentiment = predict_sentiment(tweet)\n",
        "print(predicted_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktvLClWyrPLk",
        "outputId": "1d03d438-574c-4a3e-cd7a-00d943e6d061"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n",
            "neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(r\"/content/drive/MyDrive/Airline_Sentiment_analysis/model/LSTM_Sampled.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy2etRD7wa_l",
        "outputId": "5a0d039c-fda6-4459-9b5c-093e6150d222"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTyFgxHC-dzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}